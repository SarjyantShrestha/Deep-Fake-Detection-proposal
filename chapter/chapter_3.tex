      \chapter{Requirement Analysis}
        \section{SOFTWARE REQUIREMENT}
            Our Deepfake Detection project requires following softwares:
            \subsection{Python}
                Python is a general-purpose, high-level programming language. With a strong emphasis on indentation, its design philosophy prioritizes code readability. Python uses garbage collection and dynamic typing. It is compatible with various programming paradigms, such as object-oriented, functional, and structured (especially procedural). It has an extensive standard library.

            \subsection{React}
                React is a free and open-source front-end JavaScript toolkit for creating component-based user interfaces. It is also referred to as React.js or ReactJS. It is maintained by a group of independent developers and businesses as well as Meta (previously Facebook).

            \subsection{FastAPI}
                A contemporary web framework for creating RESTful Python APIs is called FastAPI. Since its initial release in 2018, its robustness, speed, and ease of use have helped it rapidly acquire favor among developers. Based on Pydantic, FastAPI serializes and deserializes data using type hints for validation. For APIs created with it, OpenAPI documentation is also automatically generated.

            \subsection{TensorFlow}
                TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks. TensorFlow was developed by the Google Brain team for internal Google use in research and production. TensorFlow can be used in a wide variety of programming languages, including Python, JavaScript, C++, and Java.

            \subsection{Keras}
                Keras is a high-level, deep learning API developed by Google for implementing neural networks. It is written in Python and is used to make the implementation of neural networks easy. It also supports multiple backend neural network computation. Keras is relatively easy to learn and work with because it provides a python frontend with a high level of abstraction while having the option of multiple back-ends for computation purposes. It supports frameworks like tensorflow.
                
        \section{FUNCTIONAL REQUIREMENT}
            \subsection{Dataset Labeler}
                Dataset labeler is the labelling system that is used to annotate the texts as “Real”, or “Fake”.
            \subsection{Nepali News Web Scrapper}
It is the tool that extracts various Nepali text from twitter as well as various Nepali news
portals to fed into Dataset Labeler as well as vector creation process.
            \subsection{Inference System}
It is the system formed after training the model using the dataset labeled from dataset
labeler and run the prediction model in it.

        \section{NON-FUNCTIONAL REQUIREMENT}
These requirements are not needed by the system but are essential for the better
performance of sentiment engine. The points below focus on the non-functional
requirement of the system.
            \subsection{Reliability}
The system is reliable. Sentiment prediction matches 80% of the time.
            \subsection{Maintainability}
A maintainable system is created and Sentiment Analyzer Engine is able to train on
new input data and is scalable to millions of data points.
            \subsection{Performance}
The forward pass from the neural network is a fast process. For the engine, fast matrix
computation occurs.
            \subsection{Portability}
Sentiment Analyzer engine is portable and it is easy to integrate into any web
application or mobile application imaginable by the use of the REST API’s made.

        \section{FEASIBILITY STUDY}
The following points describes the feasibility of the project.
            \subsection{Economic Feasibility}
            The total expenditure of the project is just computational power. The dataset and
            computational power required for the project are easily available. Dataset is found from the internet and computational power using a powerful PC provided by the college. Therefore, the project is economically feasible.

            \subsection{Technical Feasibility}
            Although the datasets are easily available on the internet, it is estimated that it will take a large amount of time in order to train. Training huge news dataset takes a lot of computation power, with the help of the college provided machine the project is technically feasible.

            \subsection{Operational Feasibility}
            
